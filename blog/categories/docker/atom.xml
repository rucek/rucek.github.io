<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Jacek Kunicki]]></title>
  <link href="http://rucek.github.io/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://rucek.github.io/"/>
  <updated>2016-02-12T22:09:30+01:00</updated>
  <id>http://rucek.github.io/</id>
  <author>
    <name><![CDATA[Jacek Kunicki]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Multiple Entrypoints in Docker]]></title>
    <link href="http://rucek.github.io/blog/2016/02/12/multiple-entrypoints-in-docker/"/>
    <updated>2016-02-12T21:35:00+01:00</updated>
    <id>http://rucek.github.io/blog/2016/02/12/multiple-entrypoints-in-docker</id>
    <content type="html"><![CDATA[<h2>Background</h2>

<p>When using <a href="https://www.docker.com/">Docker</a> containers for a number of building blocks of your application, the recommended approach is to run a separate container for every building block, so that the components are well separated. And the <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#run-only-one-process-per-container">Docker best practices</a> suggest running a single process per container.</p>

<p>However, you may imagine a scenario in which it&rsquo;s reasonable to run multiple services in a single container (an example will follow). Then the question arises how to run those services using a single <code>ENTRYPOINT</code> command in the <code>Dockerfile</code>.</p>

<h2>Example scenario</h2>

<p>Let&rsquo;s say your application communicates with an external service through an SSH tunnel (or a VPN, or anything more than a direct connection - you name it). Then, there is a number of ways to set up the tunnel along with the application itself:</p>

<ol>
<li><p>Setup the tunnel on the host, run the container with the <code>host</code> network mode (i.e. with the <code>--net=host</code> switch) - which means that the container has no separate network stack but uses the host&rsquo;s one, so it can just access the tunnel.</p></li>
<li><p>Setup the tunnel on the host, run the container in the default network mode (i.e. <code>bridge</code>) and somehow access the tunnel on the host from the container. Somehow here means e.g. using the <code>--add-host</code> switch (with the host&rsquo;s IP) when running the container, which adds an <code>/etc/hosts</code> entry in the container (see <a href="https://docs.docker.com/engine/reference/run/#managing-etc-hosts">the docs</a> for details). Or you can try <a href="http://stackoverflow.com/questions/22944631/how-to-get-the-ip-address-of-the-docker-host-from-inside-a-docker-container">some other hacks</a> as well.</p></li>
<li><p>Run the tunnel in the container.</p></li>
</ol>


<p>Now, the problem with options 1 and 2 is that you lose the <em>run anywhere</em> part of the Docker philosophy, since <em>anywhere</em> becomes limited to <em>anywhere-with-an-ssh-tunnel</em>. Plus, your infrastructure is no more immutable, since by setting up the tunnel you just made a change to the host. A change about which you need to remember every time you run the container somewhere else.</p>

<p>Therefore, option 3 seems to be the way to go. But since Docker allows only a single <code>ENTRYPOINT</code> (to be precise, only the last <code>ENTRYPOINT</code> in the <code>Dockerfile</code> has an effect), you need to find a way to run multiple processes (the tunnel and the application) with a single command. Let&rsquo;s see how you can do it.</p>

<h2>Solution</h2>

<p>The simplest idea is to create a shell script to run the required processes and use that script as the <code>ENTRYPOINT</code>. But I wouldn&rsquo;t write a blogpost about writing a shell script, would I? Instead, let&rsquo;s dig into the recommended technique which uses <a href="http://supervisord.org/"><em>supervisord</em></a> - a process control system.</p>

<p>In the big picture, <em>supervisord</em> is a tool which lets you run multiple programs at once from a single place. The benefits over a plain old shell script are the numerous configuration and monitoring options. Here I&rsquo;m going to cover only the basic usage, which is just enough for our scenario - feel free to explore the more advanced stuff yourself.</p>

<p>To use <em>supervisord</em>, you first need to install it, preferably using a package manager. In an Ubuntu/Debian-based container you need to add the following to the <code>Dockerfile</code>:</p>

<pre><code>RUN apt-get update &amp;&amp; apt-get install -y supervisor
</code></pre>

<p>Since in this example you&rsquo;re also going to need an SSH tunnel, let&rsquo;s install the SSH client too:</p>

<pre><code>RUN apt-get update &amp;&amp; apt-get install -y supervisor openssh-client
</code></pre>

<p><strong>Note:</strong> always remember to combine <code>apt-get update</code> and <code>apt-get install</code> into a single command in order to get the latest package versions - see <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#apt-get">the docs</a> for details.</p>

<p>Now that <em>supervisord</em> and the SSH client are installed, it&rsquo;s time for some configuration. Let&rsquo;s assume that your application&rsquo;s entrypoint is <code>/opt/myapp/bin/myapp</code>. The <em>supervisord</em> configuration will then be something like:</p>

<pre><code class="ini">[supervisord]
nodaemon=true
logfile=/var/log/supervisord/supervisord.log
childlogdir=/var/log/myapp

[program:ssh]
command=ssh -N -L8080:localhost:8080 user@example.com

[program:myapp]
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
command=/opt/myapp/bin/myapp --some-configuration
</code></pre>

<p><strong>Note:</strong> If you put the congfiguration file in the defult location inside the container, i.e. <code>/etc/supervisor/conf.d/supervisord.conf</code>, it will automatically be picked up by <em>supervisord</em>. However, for the sake of this example, let&rsquo;s assume you chose a custom location inside the container, e.g. <code>/etc/myapp/supervisord.conf</code>.</p>

<p>The <code>[supervisord]</code> section configures the main <em>supervisord</em> process. The <code>nodaemon=true</code> indicates that the process should stay in the foreground (as the container would be terminated otherwise). Additionally, you can specify a log file for <em>supervisord</em> logs (with the <code>logfile</code> parameter) and a directory for the messages captured from the <code>stdout</code> and <code>stderr</code> of the child processes (here: <code>ssh</code> and <code>myapp</code>) - with the <code>childlogdir</code> parameter.</p>

<p>Next come the configurations of your processes that will run in the container.</p>

<p>For <code>ssh</code> you define your arbitrary port forwarding with the <code>-L</code> switch. Plus you can use the <code>-N</code> flag, which means that no remote command would be executed - which is <em>useful for just forwarding ports</em>, according to the SSH man page.</p>

<p>In <code>myapp</code> configuration the <code>stdout_logfile</code> parameter indicates where the <code>stdout</code> of the process should go - in this case it goes to the container&rsquo;s <code>stdout</code>. A log rotation policy can be configured  with <code>stdout_logfile_maxbytes</code>, where a value of zero means no rotation. The <code>command</code> parameter is self-explanatory - this is the full command to run your application.</p>

<p>Having configured <em>supervisord</em>, the last step is to actually run it when the container starts - with the <code>ENTRYPOINT</code> command:</p>

<pre><code>ENTRYPOINT ["/usr/bin/supervisord", "-c", "/etc/myapp/supervisord.conf"]
</code></pre>

<p>Here you can see that we use the <code>-c</code> switch to provide the path to a custom configuration file. This wouldn&rsquo;t be necessary if the configuration was in <code>/etc/supervisor/conf.d/supervisord.conf</code>.</p>

<p>After running the container you should see a few logs from <em>supervisord</em>, indicating that both the daemon and your processes have been started:</p>

<pre><code>2016-02-09 16:47:13,949 CRIT Supervisor running as root (no user in config file)
2016-02-09 16:47:13,951 INFO supervisord started with pid 1
2016-02-09 16:47:14,953 INFO spawned: 'ssh' with pid 8
2016-02-09 16:47:14,954 INFO spawned: 'myapp' with pid 9
2016-02-09 16:47:16,754 INFO success: ssh entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)
2016-02-09 16:47:16,755 INFO success: myapp entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)
</code></pre>

<h2>Summary</h2>

<p>You have just learned the recommended way to run multiple processes in a Docker container - if you know what you&rsquo;re doing, i.e. you really need more than one process in your container. Please refer to <a href="http://supervisord.org/"><em>supervisord</em> docs</a> if your scenario is anything more than this basic one.</p>
]]></content>
  </entry>
  
</feed>
