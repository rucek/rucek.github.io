<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Performance | Jacek Kunicki]]></title>
  <link href="http://rucek.github.io/blog/categories/performance/atom.xml" rel="self"/>
  <link href="http://rucek.github.io/"/>
  <updated>2017-04-12T14:52:07+02:00</updated>
  <id>http://rucek.github.io/</id>
  <author>
    <name><![CDATA[Jacek Kunicki]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Benchmarking Single-result Query Performance in Slick Using JMH]]></title>
    <link href="http://rucek.github.io/blog/2017/04/12/benchmarking-single-result-query-performance-in-slick-using-jmh/"/>
    <updated>2017-04-12T14:41:12+02:00</updated>
    <id>http://rucek.github.io/blog/2017/04/12/benchmarking-single-result-query-performance-in-slick-using-jmh</id>
    <content type="html"><![CDATA[<h2>Background</h2>

<p><a href="http://slick.lightbend.com/">Slick</a> offers a typesafe DSL for accessing your database tables as if they were Scala collections, with a similar API. However, since at the very end the DSL is translated into SQL queries, you sometimes need to be very careful how you use it. In this post you&rsquo;re going to see how a subtle difference in the query DSL can affect the performance significantly.</p>

<h2>Test case</h2>

<p>To illustrate the performance differences, we&rsquo;re going to fetch a single row from a large table defined as follows:</p>

<pre><code class="scala">case class User(id: Int, name: String)

class Users(tag: Tag) extends Table[User](tag, "users") {

  def id = column[Int]("id")

  def name = column[String]("name")

  def * = (id, name) &lt;&gt; (User.tupled, User.unapply)
}

val users = TableQuery[Users]
</code></pre>

<p>Now consider the two following queries:</p>

<pre><code class="scala">val q1 = users.result.head
val q2 = users.take(1).result.head
</code></pre>

<p>Can you tell which of those is going to be faster and why? It turns out that <code>q1</code> is going to fetch all the rows from the table and only then take the first one, while <code>q2</code> is going to add a <code>LIMIT 1</code> clause to the generated SQL query, thus reducing the number of rows fetched to one. The full generated SQL queries are, respectively:</p>

<pre><code class="sql">select "id", "name" from "users" -- q1
select "id", "name" from "users" limit 1 -- q2
</code></pre>

<p>So it&rsquo;s rather obvious that <code>q2</code> is going to be much more efficient. But let&rsquo;s check to make sure.</p>

<h2>Benchmarks</h2>

<p>To check the actual performance differences, I used <a href="http://openjdk.java.net/projects/code-tools/jmh/">JMH</a> - the Java micro benchmarking tool - and the <a href="https://github.com/ktoso/sbt-jmh">sbt-jmh plugin</a> (kudos to <a href="http://aludwikowski.blogspot.com/">Andrzej Ludwikowski</a> for recommending it!). JMH basically lets you test any part of your existing code, e.g. a single method - hence the <em>micro</em> in the name. It takes care of warming up the JVM, computing statistics etc. - the entire boilerplate you would like to skip. The benchmarks can either be configured using command-line parameters or with annotations - let&rsquo;s see how to use the latter approach.</p>

<h3>Benchmark parameters</h3>

<p>Firstly, you want to specify two types of queries to benchmark, called <code>take</code>, for the limited variant, and <code>head</code> for the second one. Secondly, you&rsquo;d like to check how the queries behave for different numbers of records in the table - let&rsquo;s assume 10k, 50k, 100k and 500k. The initial banchmark code looks like:</p>

<pre><code class="scala">@State(Scope.Benchmark)
class SingleResultBenchmark {

  @Param(Array("take", "head"))
  var queryType: String = ""

  @Param(Array("10000", "50000", "100000", "500000"))
  var numberOfRecords: Int = 0
}
</code></pre>

<p>This is certainly not the best Scala code you could imagine, but this is due to the way JMH works - the benchmarking Java code is generated by the compiler plugin based on our code, i.e. our code is instrumented by JMH. The resulting limitations are:</p>

<ul>
<li>you need to use <code>var</code>s for the parameters, so that the fields don&rsquo;t become <code>final</code> in the Java code,</li>
<li>you need to initialize the fields with some dummy values, which are not going to be used anyway (unfortunately an abstract class won&rsquo;t work),</li>
<li>all the parameters need to be specified as strings, even for numeric parameters like the <code>numberOfRecords</code>.</li>
</ul>


<p>In order to be able to declare fields (i.e. introduce some internal state) on the benchmarked class, you need to annotate it with <code>@State</code> with the scope of your choice - in our case <code>Scope.Benchmark</code> indicates that the state is going to be shared across all the threads within a single benchmark.</p>

<p>When using multiple benchmark parameters, the benchmarks are going to be executed for every possible combination of those, so in our case there are going to be 8 different benchmarks.</p>

<h3>Initialization</h3>

<p>Before running the actual benchmark, we&rsquo;d like to initialize the database (an embedded H2) with the number of records specified by the <code>numberOfRecords</code> parameter. To easily generate an arbitrary number of instances of the <code>User</code> case class, let&rsquo;s use a nice <a href="https://github.com/DanielaSfregola/random-data-generator">random-data-generator</a> library, which leverages <a href="https://github.com/rickynils/scalacheck">ScalaCheck</a> and <a href="https://github.com/alexarchambault/scalacheck-shapeless">scalacheck-shapeless</a> to provide a simple random generation API. The setup part of the benchmarking code looks like:</p>

<pre><code class="scala">private val db = Database.forConfig("h2")
private val users = TableQuery[Users]

@Setup
def prepare(): Unit = {
  val result = for {
    schemaExists &lt;- db.run(MTable.getTables(Users.TableName).headOption.map(_.nonEmpty))
    _ &lt;- if (schemaExists) Future.successful() else db.run(users.schema.create)
    _ &lt;- db.run(users.delete)
    _ &lt;- db.run(users ++= random[User](numberOfRecords))
  } yield ()

  Await.ready(result, Duration.Inf)
}
</code></pre>

<p>The <code>prepare()</code> method, annotated with <code>@Setup</code> checks if the database schema exists, creates it if it doesn&rsquo;t, then clears the <code>users</code> table and fills it with an arbitrary number of <code>User</code>s.</p>

<h3>The code under test</h3>

<p>This is the most straightforward part, since you just pick one of the queries based on the <code>queryName</code> parameter and execute it:</p>

<pre><code class="scala">private val queries = Map(
  "take" -&gt; users.take(1).result.head,
  "head" -&gt; users.result.head
)

@Benchmark
@BenchmarkMode(Array(Mode.AverageTime))
def query(): Unit = Await.ready(db.run(queries(queryType)), Duration.Inf)
</code></pre>

<p>Here, the <code>query()</code> method is annotated with <code>@Benchmark</code> to indicate that this is the actual part of the application that you want to benchmark, and with <code>BenchmarkMode</code> to indicate that you want to measure the execution time (the default mode is to measure the throughput).</p>

<h3>Results</h3>

<p>Now you&rsquo;re ready to run the benchmarks, which is as simple as:</p>

<pre><code class="``bash">  sbt jmh:run
</code></pre>

<p>Please note that with the default parameters there will be 10 forks for every parameter combination, each fork consisting of 20 warm-up iterations and 20 actual ones, which leads to quite a number of executions in total and takes some time to complete. To run fewer forks and thus reduce the time, you can e.g. add a command-line parameter:</p>

<pre><code class="``bash">  sbt "jmh:run -f 1"
</code></pre>

<p>which reduces the number of forks to one.</p>

<p>Below are the results of running the (lengthy) benchmark with the default parameters on a MacBook with 2,3 GHz Intel Core i7 and 16 GB of RAM under macOS 10.2.3 (Sierra):</p>

<pre><code class="``">  (numberOfRecords)  (queryType)  Mode  Cnt  Score    Error  Units
              10000         take  avgt  200  0.001 ±  0.001   s/op
              10000         head  avgt  200  0.008 ±  0.001   s/op
              50000         take  avgt  200  0.001 ±  0.001   s/op
              50000         head  avgt  200  0.035 ±  0.003   s/op
             100000         take  avgt  200  0.001 ±  0.001   s/op
             100000         head  avgt  200  0.064 ±  0.005   s/op
             500000         take  avgt  200  0.001 ±  0.001   s/op
             500000         head  avgt  200  3.571 ±  0.168   s/op
</code></pre>

<p>They certainly prove that the query with <code>take(1)</code> is much faster - you could even say that its performance is constant with the growing number of records, while the non-limited query tends to get slower when the record count increases (which is expected).</p>

<h2>Summary</h2>

<p>Although the Slick API resembles Scala collections a lot, you always need to remember that there&rsquo;s a database underneath and thus wisely choose how you use the API. In case you&rsquo;re not sure which of several approaches is faster, you can have a look at the actual SQL generated by Slick. When just looking at the queries is not sufficient, you can use a micro benchamrking tool like JMH to verify your guesses.</p>

<p>A full working example with the code presented above is available <a href="https://github.com/rucek/slick-single-result-performance">on GitHub</a>. Enjoy!</p>
]]></content>
  </entry>
  
</feed>
